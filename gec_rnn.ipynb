{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-07-04T16:49:25.64338Z",
     "iopub.execute_input": "2022-07-04T16:49:25.643928Z",
     "iopub.status.idle": "2022-07-04T16:49:25.655697Z",
     "shell.execute_reply.started": "2022-07-04T16:49:25.643887Z",
     "shell.execute_reply": "2022-07-04T16:49:25.654674Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grammar Error Correction with nn.Transformer and torchtext\n",
    "======================================================\n",
    "\n",
    "This notebook shows how to train a GEC model based on transformers."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Sourcing and Processing\n",
    "\n",
    "C4 200M dataset from Google Research is used in this notebook. You can find more information about the C4 200M dataset on GR's [BEA 2021 paper](https://aclanthology.org/2021.bea-1.4/).\n",
    "The already [processed dataset](https://huggingface.co/datasets/liweili/c4_200m) was extracted from Huggingface, then was transformed to HDF5 format for better manageability. The conversion process was based on this [notebook](https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-csv.ipynb).\n",
    "The final version of the dataset is uploaded on [Kaggle](https://www.kaggle.com/datasets/dariocioni/c4200m).\n",
    "\n",
    "A custom class ``Hdf5Dataset`` based on ``torch.utils.data.Dataset`` is developed, which yields a pair of source-target raw sentences.\n",
    "\n",
    "| source                                             | target                                                  |\n",
    "|----------------------------------------------------|---------------------------------------------------------|\n",
    "| Much many brands and sellers still in the market.  | Many brands and sellers still in the market.            |\n",
    "| She likes playing in park and come here every week | She likes playing in the park and comes here every week |"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Hdf5Dataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading entries from HDF5 databases\"\"\"\n",
    "\n",
    "    def __init__(self, h5_path, transform=None,num_entries = None):\n",
    "\n",
    "        self.h5f = h5py.File(h5_path, 'r')\n",
    "        if num_entries:\n",
    "            self.num_entries = num_entries\n",
    "        else:\n",
    "            self.num_entries = self.h5f['labels'].shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index > self.num_entries:\n",
    "            raise StopIteration\n",
    "        input = self.h5f['input'][index].decode('utf-8')\n",
    "        label = self.h5f['labels'][index].decode('utf-8')\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(input)\n",
    "        return input, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "from tqdm import tqdm\n",
    "import pathlib as pl\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, index: int) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in tqdm(data_iter):\n",
    "        if data_sample[index] and isinstance(data_sample[index],str):\n",
    "            yield token_transform(data_sample[index])\n",
    "\n",
    "SRC_LANGUAGE = 'incorrect'\n",
    "TGT_LANGUAGE = 'correct'\n",
    "MAX_LENGTH = 2048\n",
    "VOCAB_SIZE = 20000\n",
    "N_SAMPLES = 10000\n",
    "\n",
    "# # Define special symbols and indices\n",
    "UNK_IDX,PAD_IDX, BOS_IDX, EOS_IDX = 0,1,2,3\n",
    "# # Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<pad>','<unk>', '[CLS]', '[SEP]']\n",
    "\n",
    "# Place-holders\n",
    "token_transform =get_tokenizer('basic_english')\n",
    "vocab_transform = None\n",
    "\n",
    "folder = 'D:\\Datasets\\c4_200m\\data\\hdf5'\n",
    "train_filename = 'C4_200M.hf5-00000-of-00010'\n",
    "valid_filename = 'C4_200M.hf5-00001-of-00010'\n",
    "embedding_path = 'D:\\Datasets\\glove\\glove.42B.300d.txt'\n",
    "checkpoint_folder = 'D:\\Datasets\\c4_200m\\checkpoints'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizing and Embedding\n",
    "Data is then tokenized by the standard tokenizer from ``torchtext`` library, which performs basic normalization and splitting by space. Normalization includes\n",
    "- lowercasing\n",
    "- complete some basic text normalization for English words as follows:\n",
    "    add spaces before and after '\\''\n",
    "    remove '\\\"',\n",
    "    add spaces before and after '.'\n",
    "    replace '<br \\/>'with single space\n",
    "    add spaces before and after ','\n",
    "    add spaces before and after '('\n",
    "    add spaces before and after ')'\n",
    "    add spaces before and after '!'\n",
    "    add spaces before and after '?'\n",
    "    replace ';' with single space\n",
    "    replace ':' with single space\n",
    "    replace multiple spaces with single space\n",
    "\n",
    "A tokenization library like ``spacy`` could be better and will be evaluated in future.\n",
    "\n",
    "The embedding will be performed with pretrained ``GloVe`` Embeddings, which were trained on Common Crawl (42B tokens, 1.9M vocab, uncased, 300d vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "vocab_transform = torch.load(pl.Path(checkpoint_folder)/'vocab.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collation\n",
    "---------\n",
    "\n",
    "As seen in the ``Data Sourcing and Processing`` section, our data iterator yields a pair of raw strings. We need to convert these string pairs into the batched tensors that can be processed by our ``Seq2Seq`` network defined previously. Below we define our collate function that convert batch of raw strings into batch tensors that can be fed directly into our model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# def glove_transform(tokens: List[str]):\n",
    "\n",
    "\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = sequential_transforms(token_transform,\n",
    "                                               vocab_transform,\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform(src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform(tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's finally see all the three steps of conversion of a sentence to an embedding tensor."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized input:\n",
      " ['data', 'mining', 'is', 'awesome', '!']\n",
      "encoded input:\n",
      " [157, 1185, 13, 1480, 32]\n",
      "transformed input:\n",
      " tensor([   2,  157, 1185,   13, 1480,   32,    3])\n"
     ]
    }
   ],
   "source": [
    "text = 'data mining is awesome!'\n",
    "tokenized_input = token_transform(text)\n",
    "print(\"tokenized input:\\n\",tokenized_input)\n",
    "\n",
    "encoded_input = vocab_transform(tokenized_input)\n",
    "print(\"encoded input:\\n\",encoded_input)\n",
    "\n",
    "print(\"transformed input:\\n\",text_transform(text))\n",
    "\n",
    "# my_embedding_layer = torch.nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float())\n",
    "# assert my_embedding_layer.weight.shape == embs_npa.shape\n",
    "# embedding1 = my_embedding_layer(tensor_transform(encoded_input))\n",
    "# print(embedding1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unknown words\n",
    "In this version, unknown words are all converted to <unk> and converted to the same embedding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataminingisawesome', '!']\n",
      "[0, 32]\n"
     ]
    }
   ],
   "source": [
    "text = 'dataminingisawesome!'\n",
    "tokenized_input = token_transform(text)\n",
    "print(tokenized_input)\n",
    "\n",
    "encoded_input = vocab_transform(tokenized_input)\n",
    "print(encoded_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN Network\n",
    "This network is a seq2seq network composed by GRU layers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "torch.manual_seed(0)\n",
    "\n",
    "EMB_SIZE = 300\n",
    "NHEAD = 5\n",
    "HIDDEN_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 1\n",
    "NUM_DECODER_LAYERS =1\n",
    "\n",
    "learning_rate = 0.0001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let's define a function that will take care of both."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, trg in tqdm(iterator):\n",
    "\n",
    "        src = src.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for src, trg in tqdm(iterator):\n",
    "\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now define the parameters of our model and instantiate the same. Below, we also define our loss function which is the cross-entropy loss and the optmizer used for training.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 29,313,696 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "from models.rnn_seq2seq import Encoder, Decoder, Seq2Seq\n",
    "\n",
    "encoder1 = Encoder(VOCAB_SIZE,EMB_SIZE,HIDDEN_SIZE,0).to(DEVICE)\n",
    "decoder1 = Decoder(VOCAB_SIZE,EMB_SIZE,HIDDEN_SIZE,dropout=0.1).to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(encoder1.parameters(), lr = learning_rate , betas=(0.9, 0.98), eps=1e-9)\n",
    "#decoder_optimizer = torch.optim.Adam(encoder1.parameters(), lr = learning_rate, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model = Seq2Seq(encoder1,decoder1,DEVICE)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have all the ingredients to train our model. Let's do it!\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:56<00:00,  1.77it/s]\n",
      "100%|██████████| 313/313 [00:59<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 10.012, Val loss: 9.994, Epoch time = 176.590s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/313 [00:12<03:23,  1.43it/s]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 2\n",
    "CLIP = 1\n",
    "\n",
    "train_iter = Hdf5Dataset(pl.Path(folder)/train_filename,num_entries=N_SAMPLES)\n",
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_iter = Hdf5Dataset(pl.Path(folder)/valid_filename,num_entries=N_SAMPLES)\n",
    "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(model,train_dataloader,optimizer,loss_fn,0)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(model,val_dataloader,loss_fn)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'encoder_optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': val_loss,\n",
    "    }, pl.Path('checkpoints')/\"model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# function to generate output sequence using greedy algorithm \n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to correct input sentence\n",
    "def correct(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return  ''.join(tokenizer.decode(tgt_tokens.cpu()))#.replace('[CLS]', '').replace('[SEP]', ''))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = 'I am 25 years olde'\n",
    "\n",
    "tensor = text_transform(text)\n",
    "output_words = evaluate(\n",
    "    model, tensor)\n",
    "print('input =', text)\n",
    "print('output =', ' '.join(output_words))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_iter = Hdf5Dataset(pl.Path(folder)/valid_filename)\n",
    "for i in range(0,99):\n",
    "    e = val_iter[10000000+i]\n",
    "    print(i,\"input: \",e[0],\"\\n  correct: \",correct(transformer, e[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "References\n",
    "----------\n",
    "\n",
    "1. Attention is all you need paper.\n",
    "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "2. The annotated transformer. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}